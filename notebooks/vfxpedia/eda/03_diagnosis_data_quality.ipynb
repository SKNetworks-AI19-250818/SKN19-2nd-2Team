{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 진단 및 문제 파악\n",
    "\n",
    "분석 결과에서 \"정의되지 않은 코드\" 문제를 파악하고 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.var_mapping'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvar_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VAR_DICT, get_var_info\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[32m      9\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m../../data/analy_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'data.var_mapping'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 프로젝트 루트를 Python 경로에 추가\n",
    "project_root = os.path.abspath('../../..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.variable_decoder import VariableDecoder\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('../../../data/analy_data.csv')\n",
    "print(f\"데이터 shape: {df.shape}\")\n",
    "\n",
    "# VariableDecoder 초기화\n",
    "decoder = VariableDecoder()\n",
    "print('✅ VariableDecoder 초기화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 각 변수의 실제 코드값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석 대상 변수\n",
    "analysis_vars = ['sob_01z1', 'sob_02z1', 'soa_01z1', 'soa_06z2', 'soa_07z1', 'sod_02z3']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"📊 각 변수의 실제 코드값 분포\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "undefined_issues = []  # 문제 수집\n",
    "\n",
    "for var in analysis_vars:\n",
    "    var_label = decoder.get_variable_label(var)\n",
    "    print(f\"\\n### {var} - {var_label}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 실제 데이터의 코드값\n",
    "    actual_values = df[var].value_counts().sort_index()\n",
    "    print(\"\\n실제 데이터의 코드값:\")\n",
    "    print(actual_values)\n",
    "    \n",
    "    # VariableDecoder에 정의된 코드값\n",
    "    code_mapping = decoder.get_code_mapping(var)\n",
    "    if code_mapping:\n",
    "        defined_codes = set(code_mapping.keys())\n",
    "        print(f\"\\nVariableDecoder에 정의된 코드: {sorted(defined_codes)}\")\n",
    "        \n",
    "        # 정의되지 않은 코드 찾기\n",
    "        actual_codes = set(actual_values.index.dropna())\n",
    "        undefined_codes = actual_codes - defined_codes\n",
    "        \n",
    "        if undefined_codes:\n",
    "            print(f\"\\n⚠️ 정의되지 않은 코드: {sorted(undefined_codes)}\")\n",
    "            print(f\"   해당 코드의 빈도:\")\n",
    "            for code in sorted(undefined_codes):\n",
    "                count = actual_values.get(code, 0)\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"     {code}: {count}건 ({pct:.2f}%)\")\n",
    "                undefined_issues.append({\n",
    "                    '변수': var,\n",
    "                    '변수명': var_label,\n",
    "                    '코드': code,\n",
    "                    '건수': count,\n",
    "                    '비율(%)': f\"{pct:.2f}\"\n",
    "                })\n",
    "        else:\n",
    "            print(\"\\n✅ 모든 코드가 정의되어 있음\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ VariableDecoder에 매핑 정보 없음\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. churn 변수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 타겟 변수 (churn) 분석\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n분포:\")\n",
    "print(df['churn'].value_counts())\n",
    "print(f\"\\n결측값: {df['churn'].isna().sum()}건\")\n",
    "print(f\"금연 성공률: {df['churn'].mean() * 100:.2f}%\")\n",
    "\n",
    "# churn이 있는 데이터만 필터링\n",
    "df_with_churn = df[df['churn'].notna()]\n",
    "print(f\"\\nchurn이 있는 데이터: {len(df_with_churn)}건 ({len(df_with_churn)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 변수별 결측값 및 특수코드 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 변수별 데이터 품질 분석\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "quality_report = []\n",
    "\n",
    "for var in analysis_vars:\n",
    "    var_label = decoder.get_variable_label(var)\n",
    "    \n",
    "    # 결측값\n",
    "    na_count = df[var].isna().sum()\n",
    "    na_pct = na_count / len(df) * 100\n",
    "    \n",
    "    # 특수코드 (응답거부, 모름, 비해당 등)\n",
    "    special_codes = []\n",
    "    special_count = 0\n",
    "    \n",
    "    code_mapping = decoder.get_code_mapping(var)\n",
    "    if code_mapping:\n",
    "        for code, label in code_mapping.items():\n",
    "            if any(keyword in str(label) for keyword in ['응답거부', '모름', '비해당']):\n",
    "                special_codes.append(code)\n",
    "                special_count += (df[var] == code).sum()\n",
    "    \n",
    "    special_pct = special_count / len(df) * 100\n",
    "    \n",
    "    # 유효 데이터\n",
    "    valid_count = len(df) - na_count - special_count\n",
    "    valid_pct = valid_count / len(df) * 100\n",
    "    \n",
    "    quality_report.append({\n",
    "        '변수': var_label,\n",
    "        '전체': len(df),\n",
    "        '결측값': f\"{na_count} ({na_pct:.1f}%)\",\n",
    "        '특수코드': f\"{special_count} ({special_pct:.1f}%)\",\n",
    "        '유효데이터': f\"{valid_count} ({valid_pct:.1f}%)\"\n",
    "    })\n",
    "\n",
    "quality_df = pd.DataFrame(quality_report)\n",
    "print(quality_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 교차 분석: churn과 함께 유효한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 churn과 함께 분석 가능한 데이터\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "churn_quality = []\n",
    "\n",
    "for var in analysis_vars:\n",
    "    var_label = decoder.get_variable_label(var)\n",
    "    \n",
    "    # churn과 해당 변수 모두 유효한 데이터\n",
    "    both_valid = df[(df['churn'].notna()) & (df[var].notna())]\n",
    "    \n",
    "    # 특수코드 제외\n",
    "    code_mapping = decoder.get_code_mapping(var)\n",
    "    if code_mapping:\n",
    "        special_codes = [\n",
    "            code for code, label in code_mapping.items()\n",
    "            if any(keyword in str(label) for keyword in ['응답거부', '모름', '비해당'])\n",
    "        ]\n",
    "        both_valid_clean = both_valid[~both_valid[var].isin(special_codes)]\n",
    "    else:\n",
    "        both_valid_clean = both_valid\n",
    "    \n",
    "    churn_quality.append({\n",
    "        '변수': var_label,\n",
    "        '원본 데이터': len(df),\n",
    "        '분석 가능': len(both_valid_clean),\n",
    "        '비율(%)': f\"{len(both_valid_clean)/len(df)*100:.1f}\",\n",
    "        '금연성공률(%)': f\"{both_valid_clean['churn'].mean()*100:.1f}\"\n",
    "    })\n",
    "\n",
    "churn_quality_df = pd.DataFrame(churn_quality)\n",
    "print(churn_quality_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 진단 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 진단 결과 요약 및 권장 조치\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n### 1️⃣ 정의되지 않은 코드값\")\n",
    "if undefined_issues:\n",
    "    print(f\"\\n⚠️ 총 {len(undefined_issues)}개의 정의되지 않은 코드 발견\")\n",
    "    undefined_df = pd.DataFrame(undefined_issues)\n",
    "    print(\"\\n\" + undefined_df.to_string(index=False))\n",
    "    print(\"\\n→ 조치: var_mapping.py에 위 코드값 추가 필요\")\n",
    "else:\n",
    "    print(\"\\n✅ 모든 코드값이 정의되어 있음\")\n",
    "\n",
    "print(\"\\n### 2️⃣ 데이터 정제 방안\")\n",
    "print(\"\\n✅ 권장: 특수코드(응답거부, 모름, 비해당) 제거\")\n",
    "print(\"✅ 권장: 결측값 제거\")\n",
    "print(\"⚠️ 주의: 제거 후 표본 크기 충분성 확인 필요\")\n",
    "\n",
    "print(\"\\n### 3️⃣ 분석 가능 표본 크기\")\n",
    "min_sample = churn_quality_df['분석 가능'].min()\n",
    "print(f\"\\n최소 표본 크기: {min_sample:,}건\")\n",
    "\n",
    "# 숫자로 변환하여 비교\n",
    "if min_sample > 1000:\n",
    "    print(\"✅ 충분한 표본 크기 확보\")\n",
    "elif min_sample > 500:\n",
    "    print(\"⚠️ 표본 크기가 다소 작음. 해석 시 주의 필요\")\n",
    "else:\n",
    "    print(\"❌ 표본 크기가 매우 작음. 통계적 검정력 부족 우려\")\n",
    "\n",
    "print(\"\\n### 4️⃣ 다음 단계\")\n",
    "print(\"\\n1. variable.csv 업데이트 (정의되지 않은 코드 추가)\")\n",
    "print(\"2. 데이터 정제 스크립트 실행\")\n",
    "print(\"3. 분석 재실행\")\n",
    "print(\"4. 특성 중요도 분석 추가\")\n",
    "print(\"5. 최종 해석 및 보고서 작성\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ 진단 완료!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 체크리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📋 체크리스트\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n✅ 데이터 기본 정보:\")\n",
    "print(f\"   - 전체 데이터: {len(df):,}건\")\n",
    "print(f\"   - churn 있는 데이터: {len(df_with_churn):,}건\")\n",
    "print(f\"   - 전체 금연 성공률: {df['churn'].mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n✅ 정의되지 않은 코드:\")\n",
    "if undefined_issues:\n",
    "    print(f\"   ⚠️ {len(undefined_issues)}개 발견\")\n",
    "    for issue in undefined_issues:\n",
    "        print(f\"   - {issue['변수명']}: 코드 {issue['코드']} ({issue['건수']:,}건, {issue['비율(%)']}%)\")\n",
    "else:\n",
    "    print(\"   ✅ 없음\")\n",
    "\n",
    "print(f\"\\n✅ 분석 가능 표본:\")\n",
    "print(f\"   - 최소: {churn_quality_df['분석 가능'].min():,}건\")\n",
    "print(f\"   - 최대: {churn_quality_df['분석 가능'].max():,}건\")\n",
    "\n",
    "print(f\"\\n✅ 특이사항:\")\n",
    "# 표본이 가장 작은 변수\n",
    "min_idx = churn_quality_df['분석 가능'].idxmin()\n",
    "print(f\"   - 표본이 가장 작은 변수: {churn_quality_df.loc[min_idx, '변수']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"💡 이 정보를 최적화된 분석 노트북을 생성합니다!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


